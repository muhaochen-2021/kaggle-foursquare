{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b55b42",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-05T14:12:58.129130Z",
     "iopub.status.busy": "2022-07-05T14:12:58.128530Z",
     "iopub.status.idle": "2022-07-05T14:13:11.771937Z",
     "shell.execute_reply": "2022-07-05T14:13:11.770988Z",
     "shell.execute_reply.started": "2022-07-05T14:03:20.827021Z"
    },
    "papermill": {
     "duration": 13.690109,
     "end_time": "2022-07-05T14:13:11.772092",
     "exception": false,
     "start_time": "2022-07-05T14:12:58.081983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "import cudf\n",
    "import cupy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# For Transformer Models\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, AutoConfig\n",
    "\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.metrics import pairwise_distances\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    seed = 42 # 随机种子\n",
    "    device = torch.device('cuda') # GPU\n",
    "\n",
    "    epochs = 30 # 训练 epochs\n",
    "    lr = 5e-5 # 学习率\n",
    "    max_length = 64 # 最大长度\n",
    "\n",
    "    # Arcface\n",
    "    s = 30.0 # arcface 参数 scale\n",
    "    m = 0.5  # arcface 参数 margin\n",
    "    ls_eps = 0.0 # arcface 参数 eps\n",
    "    easy_margin = False # easy_margin\n",
    "    n_classes = 739972 # 分类数量\n",
    "    \n",
    "    \n",
    "# 四个模型\n",
    "class CFG_Model1:\n",
    "    model_name = \"../input/huggingface-roberta-variants/xlm-roberta-large/xlm-roberta-large\" \n",
    "    weight = \"../input/model1/xlm-roberta-large_epoch30.bin\"\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class CFG_Model2:\n",
    "    model_name = \"../input/sentence-transformers/LaBSE/0_Transformer\"\n",
    "    weight = \"../input/model2/0_Transformer_epoch30.bin\"\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "class CFG_Model3:\n",
    "    model_name = \"../input/paraphrasemultilingualmpnetbasev2/paraphrase-multilingual-mpnet-base-v2\"\n",
    "    weight = \"../input/model3/paraphrase-multilingual-mpnet-base-v2_epoch30.bin\"\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "class CFG_Model4:\n",
    "    model_name = \"../input/rembert-pt\"\n",
    "    weight = \"../input/model4/rembert-pt_epoch30.bin\"\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8eb18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:13:24.081768Z",
     "iopub.status.busy": "2022-07-05T14:13:24.078581Z",
     "iopub.status.idle": "2022-07-05T14:13:25.357703Z",
     "shell.execute_reply": "2022-07-05T14:13:25.358175Z",
     "shell.execute_reply.started": "2022-07-05T14:03:56.543699Z"
    },
    "papermill": {
     "duration": 1.318549,
     "end_time": "2022-07-05T14:13:25.358324",
     "exception": false,
     "start_time": "2022-07-05T14:13:24.039775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.csv\n",
    "df_train = cudf.read_csv(\"../input/trainfilled/train_filled.csv\", dtype={\n",
    "    \"id\": str, \"name\": str, \"latitude\": float, \"longitude\": float, \"address\": str, \n",
    "    \"city\": str, \"state\": str, \"zip\": str, \"country\": str, \"url\": str, \"phone\": str, \"categories\": str, \"point_of_interest\": str\n",
    "})\n",
    "\n",
    "\n",
    "for col in [\"name\", \"address\", \"city\", \"state\", \"zip\", \"country\", \"url\", \"phone\", \"categories\"]:\n",
    "    df_train[col] = df_train[col].fillna(\"\") # 对空值填充空字符串\n",
    "\n",
    "# fulltext = 拼接name、address、city、state、country、categories\n",
    "df_train[\"fulltext\"] = (\n",
    "    df_train[\"name\"] + \" \" + df_train[\"address\"] + \" \" + df_train[\"city\"] + \" \" + df_train[\"state\"] + \" \"  + df_train[\"country\"] + \" \" + df_train[\"categories\"]\n",
    ").to_pandas().replace(r'\\s+', ' ', regex=True) # \n",
    "\n",
    "# Standardization of coordinates.\n",
    "# https://datascience.stackexchange.com/questions/13567/ways-to-deal-with-longitude-latitude-feature\n",
    "df_train[\"coord_x\"] = cupy.cos(df_train[\"latitude\"]) * cupy.cos(df_train[\"longitude\"]) # 经度和纬度转换成x坐标\n",
    "df_train[\"coord_y\"] = cupy.cos(df_train[\"latitude\"]) * cupy.sin(df_train[\"longitude\"]) # 经度和纬度转换成y坐标\n",
    "df_train[\"coord_z\"] = cupy.sin(df_train[\"latitude\"]) # 经度和纬度转换成z坐标\n",
    "\n",
    "\n",
    "encoder = LabelEncoder() # 创建标签编码器\n",
    "df_train['point_of_interest'] = encoder.fit_transform(df_train['point_of_interest'].to_array()) # 对point_of_interest做编码标签\n",
    "                       \n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1799d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:13:25.433852Z",
     "iopub.status.busy": "2022-07-05T14:13:25.433149Z",
     "iopub.status.idle": "2022-07-05T14:13:25.438405Z",
     "shell.execute_reply": "2022-07-05T14:13:25.437951Z",
     "shell.execute_reply.started": "2022-07-05T14:03:57.902007Z"
    },
    "papermill": {
     "duration": 0.045438,
     "end_time": "2022-07-05T14:13:25.438520",
     "exception": false,
     "start_time": "2022-07-05T14:13:25.393082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa9486",
   "metadata": {
    "papermill": {
     "duration": 0.034606,
     "end_time": "2022-07-05T14:13:25.578109",
     "exception": false,
     "start_time": "2022-07-05T14:13:25.543503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load ArcFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe40834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:13:25.658204Z",
     "iopub.status.busy": "2022-07-05T14:13:25.657332Z",
     "iopub.status.idle": "2022-07-05T14:13:25.659185Z",
     "shell.execute_reply": "2022-07-05T14:13:25.659626Z",
     "shell.execute_reply.started": "2022-07-05T14:03:57.918656Z"
    },
    "papermill": {
     "duration": 0.04742,
     "end_time": "2022-07-05T14:13:25.659774",
     "exception": false,
     "start_time": "2022-07-05T14:13:25.612354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FourSquareDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.fulltext = df['fulltext'].values # 全文\n",
    "        self.latitudes = df['latitude'].values # 纬度\n",
    "        self.longitudes = df['longitude'].values # 经度\n",
    "        self.coord_x = df['coord_x'].values # 经纬度坐标 x\n",
    "        self.coord_y = df['coord_y'].values # 经纬度坐标 y\n",
    "        self.coord_z = df['coord_z'].values # 经纬度坐标 z\n",
    "        self.labels = df['point_of_interest'].values # point_of_interest 标签\n",
    "        self.tokenizer = tokenizer # 词表\n",
    "        self.max_length = max_length # 最大长度\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fulltext) # 返回数据长度\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fulltext = self.fulltext[index] # 全文\n",
    "        latitude = self.latitudes[index] # 纬度\n",
    "        longitude = self.longitudes[index] # 经度\n",
    "        label = self.labels[index] # 标签\n",
    "        coord_x = self.coord_x[index] # 经纬度坐标 x\n",
    "        coord_y = self.coord_y[index] # 经纬度坐标 y\n",
    "        coord_z = self.coord_z[index] # 经纬度坐标 z\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            fulltext, # 全文\n",
    "            truncation=True, # 截断\n",
    "            add_special_tokens=True, # 添加特殊字符\n",
    "            max_length=self.max_length, # 最大长度\n",
    "            padding='max_length', # 填充方式\n",
    "            return_tensors=\"pt\" # 返回张量\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': inputs['input_ids'][0], # input_ids\n",
    "            'mask': inputs['attention_mask'][0], # 注意力掩码\n",
    "            'latitude': torch.tensor(latitude, dtype=torch.float), # 纬度\n",
    "            'longitude': torch.tensor(longitude, dtype=torch.float), # 经度\n",
    "            'coord_x': torch.tensor(coord_x), # 经纬度坐标 x\n",
    "            'coord_y': torch.tensor(coord_y), # 经纬度坐标 y\n",
    "            'coord_z': torch.tensor(coord_z), # 经纬度坐标 z\n",
    "            'label': torch.tensor(label, dtype=torch.long) # 标签\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ddfb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:13:25.749275Z",
     "iopub.status.busy": "2022-07-05T14:13:25.748455Z",
     "iopub.status.idle": "2022-07-05T14:13:25.750914Z",
     "shell.execute_reply": "2022-07-05T14:13:25.750455Z",
     "shell.execute_reply.started": "2022-07-05T14:03:57.942142Z"
    },
    "papermill": {
     "duration": 0.056618,
     "end_time": "2022-07-05T14:13:25.751036",
     "exception": false,
     "start_time": "2022-07-05T14:13:25.694418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arcface\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, \n",
    "                 m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features  # input的维度\n",
    "        self.out_features = out_features # output的维度\n",
    "        self.s = s # re-scale\n",
    "        self.m = m # margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        # 初始化权重\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin # easy_margin 模式\n",
    "        self.cos_m = math.cos(m) # cos margin\n",
    "        self.sin_m = math.sin(m) # sin margin\n",
    "        self.threshold = math.cos(math.pi - m) # cos(pi - m) = -cos(m)\n",
    "        self.mm = math.sin(math.pi - m) * m # sin(pi - m)*m = sin(m)*m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight)) # 获得cosθ (vector)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2)) # 获得cosθ\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m # cosθ*cosm – sinθ*sinm = cos(θ + m)\n",
    "        phi = phi.float() # phi to float\n",
    "        cosine = cosine.float() # cosine to float\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            # 以下代码控制了 θ+m 应该在 range[0, pi]\n",
    "            # if cos(θ) > cos(pi - m) means θ + m < math.pi, so phi = cos(θ + m);\n",
    "            # else means θ + m >= math.pi, we use Talyer extension to approximate the cos(θ + m).\n",
    "            # if fact, cos(θ + m) = cos(θ) - m * sin(θ) >= cos(θ) - m * sin(math.pi - m)\n",
    "            phi = torch.where(cosine > self.threshold, phi, cosine - self.mm) # https://github.com/ronghuaiyang/arcface-pytorch/issues/48\n",
    "        # --------------------------- convert label to one-hot ---------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        # 对label形式进行转换，假设batch为2、有3类的话，即将label从[1,2]转换成[[0,1,0],[0,0,1]]\n",
    "        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        # 进行re-scale\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "class FSMultiModalNet(nn.Module):\n",
    "    def __init__(self, model_name, fc_dim, num_features=3):\n",
    "        super(FSMultiModalNet, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name) # 加载预训练模型\n",
    "        self.bert_model = AutoModel.from_pretrained(model_name, config=self.config) # 加载预训练模型\n",
    "        # self.embedding = nn.Linear(self.config.hidden_size + 2, embedding_size)\n",
    "\n",
    "        self.fc = nn.Linear(self.bert_model.config.hidden_size + num_features, fc_dim) # 全连接层 hidden_size + x'y'z'\n",
    "        self.bn = nn.BatchNorm1d(fc_dim) # BatchNorm1d\n",
    "        self._init_params() # 初始化参数\n",
    "\n",
    "        self.margin = ArcMarginProduct(\n",
    "            fc_dim, # 输入维度\n",
    "            CFG.n_classes, # 输出维度\n",
    "            s=CFG.s, # scale\n",
    "            m=CFG.m, # margin \n",
    "            easy_margin=CFG.easy_margin, # easy_margin\n",
    "            ls_eps=CFG.ls_eps # label smoothing epsilon\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight) # 初始化全连接层权重\n",
    "        nn.init.constant_(self.fc.bias, 0) # 初始化全连接层偏置\n",
    "        nn.init.constant_(self.bn.weight, 1) # 初始化 BatchNorm1d 权重\n",
    "        nn.init.constant_(self.bn.bias, 0) # 初始化 BatchNorm1d 偏置\n",
    "\n",
    "    def forward(self, ids, mask, lat, lon, coord_x, coord_y, coord_z, labels):\n",
    "        feature = self.extract_feature(ids, mask, lat, lon, coord_x, coord_y, coord_z) # 提取特征\n",
    "        output = self.margin(feature, labels) # ArcMarginProduct 输出\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def extract_feature(self, input_ids, attention_mask, lat, lon, coord_x, coord_y, coord_z):\n",
    "        x = self.bert_model(input_ids=input_ids, attention_mask=attention_mask) # 获取 BERT 特征\n",
    "        x = torch.sum(x.last_hidden_state * attention_mask.unsqueeze(-1), dim=1) / attention_mask.sum(dim=1, keepdims=True) # 将 BERT 特征attention_mask部分求平均\n",
    "\n",
    "        x = torch.cat([x, coord_x.view(-1, 1), coord_y.view(-1, 1), coord_z.view(-1, 1)], axis=1) # 将 bert输出 和 x'y'z' 合并\n",
    "\n",
    "        x = self.fc(x) # 全连接层\n",
    "        x = self.bn(x) # BatchNorm1d\n",
    "\n",
    "        return x # 返回特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = CFG_Model3.model_name\n",
    "model_arch = model_name.split(\"/\")[-1]\n",
    "tokenizer = CFG_Model3.tokenizer\n",
    "\n",
    "model = FSMultiModalNet(model_name, 320) # 初始化模型\n",
    "model.to(CFG.device); # 将模型转到GPU\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=CFG.lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1201a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FourSquareDataset(df_train.to_pandas(), tokenizer=tokenizer, max_length=CFG.max_length) # Dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, num_workers=2, shuffle=True, pin_memory=True) # DataLoader\n",
    "def train_fn(model, dataloader):\n",
    "    model.train()\n",
    "    bar = tqdm(dataloader)\n",
    "    losses = []\n",
    "    for idx, data in enumerate(bar): \n",
    "        ids = data['ids'].to(CFG.device, dtype=torch.long) # input_ids\n",
    "        mask = data['mask'].to(CFG.device, dtype=torch.long) # attention_mask\n",
    "        latitude =  data['latitude'].to(CFG.device, dtype=torch.float) # latitude\n",
    "        longitude = data['longitude'].to(CFG.device, dtype=torch.float) # longitude\n",
    "        coord_x =   data['coord_x'].to(CFG.device, dtype=torch.float) # coord_x\n",
    "        coord_y =   data['coord_y'].to(CFG.device, dtype=torch.float) # coord_y\n",
    "        coord_z =   data['coord_z'].to(CFG.device, dtype=torch.float) # coord_z\n",
    "        labels =    data['label'].to(CFG.device, dtype=torch.long) # label\n",
    "\n",
    "        optimizer.zero_grad()  # 优化器置零\n",
    "        y_preds = model(ids, mask, latitude, longitude, coord_x, coord_y, coord_z, labels) # 把数据放入模型训练\n",
    "        loss = criterion(y_preds, labels) # 计算loss\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 优化器迭代\n",
    "\n",
    "        losses.append(loss.item()) # 存下当前的loss\n",
    "        smooth_loss = np.mean(losses[-30:]) # 求近30步的平均loss\n",
    "        bar.set_description(f'loss: {loss.item():.5f}, smth: {smooth_loss:.5f}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}') # 更新进度条\n",
    "    loss_train = np.mean(losses) # 求全体平均loss    \n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f00bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(CFG.epochs):\n",
    "    loss_train = train_fn(model, dataloader)\n",
    "    torch.save(model.state_dict(), f'{model_arch}_epoch{epoch}.bin')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"{epoch} Training loss    : {loss_train:.4f}\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e77c61",
   "metadata": {},
   "source": [
    "# Get Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4424b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_csv(\"../input/trainfilled/train_filled.csv\", dtype={\n",
    "    \"id\": str, \"name\": str, \"latitude\": float, \"longitude\": float, \"address\": str, \n",
    "    \"city\": str, \"state\": str, \"zip\": str, \"country\": str, \"url\": str, \"phone\": str, \"categories\": str, \"point_of_interest\": str\n",
    "})\n",
    "\n",
    "\n",
    "for col in [\"name\", \"address\", \"city\", \"state\", \"zip\", \"country\", \"url\", \"phone\", \"categories\"]:\n",
    "    df[col] = df[col].fillna(\"\") # 对空值填充空字符串\n",
    "\n",
    "# fulltext = 拼接name、address、city、state、country、categories\n",
    "df[\"fulltext\"] = (\n",
    "    df[\"name\"] + \" \" + df[\"address\"] + \" \" + df[\"city\"] + \" \" + df[\"state\"] + \" \"  + df[\"country\"] + \" \" + df[\"categories\"]\n",
    ").to_pandas().replace(r'\\s+', ' ', regex=True) # \n",
    "\n",
    "# Standardization of coordinates.\n",
    "# https://datascience.stackexchange.com/questions/13567/ways-to-deal-with-longitude-latitude-feature\n",
    "df[\"coord_x\"] = cupy.cos(df[\"latitude\"]) * cupy.cos(df[\"longitude\"]) # 经度和纬度转换成x坐标\n",
    "df[\"coord_y\"] = cupy.cos(df[\"latitude\"]) * cupy.sin(df[\"longitude\"]) # 经度和纬度转换成y坐标\n",
    "df[\"coord_z\"] = cupy.sin(df[\"latitude\"]) # 经度和纬度转换成z坐标\n",
    "\n",
    "\n",
    "encoder = LabelEncoder() # 创建标签编码器\n",
    "df['point_of_interest'] = encoder.fit_transform(df['point_of_interest'].to_array()) # 对point_of_interest做编码标签\n",
    "                       \n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc9dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:13:25.834652Z",
     "iopub.status.busy": "2022-07-05T14:13:25.833751Z",
     "iopub.status.idle": "2022-07-05T14:13:25.835514Z",
     "shell.execute_reply": "2022-07-05T14:13:25.835900Z",
     "shell.execute_reply.started": "2022-07-05T14:03:57.981422Z"
    },
    "papermill": {
     "duration": 0.049526,
     "end_time": "2022-07-05T14:13:25.836039",
     "exception": false,
     "start_time": "2022-07-05T14:13:25.786513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embed(model,tokenizer):\n",
    "    # NN embeddings \n",
    "    dataset = FourSquareDataset(df.to_pandas(), tokenizer=tokenizer, max_length=CFG.max_length) # Dataset\n",
    "    loader = DataLoader(dataset, batch_size=256, num_workers=5, shuffle=False, pin_memory=True) # DataLoader\n",
    "\n",
    "    embeds = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader): \n",
    "            ids = data['ids'].to(CFG.device, dtype=torch.long) # input_ids\n",
    "            mask = data['mask'].to(CFG.device, dtype=torch.long) # attention_mask\n",
    "\n",
    "            latitude = data['latitude'].to(CFG.device, dtype=torch.float) # latitude\n",
    "            longitude = data['longitude'].to(CFG.device, dtype=torch.float) # longitude\n",
    "            coord_x = data['coord_x'].to(CFG.device, dtype=torch.float) # coord_x\n",
    "            coord_y = data['coord_y'].to(CFG.device, dtype=torch.float) # coord_y\n",
    "            coord_z = data['coord_z'].to(CFG.device, dtype=torch.float) # coord_z\n",
    "            # labels = data['label'].to(CFG.device, dtype=torch.long)\n",
    "\n",
    "            emb = model.extract_feature(ids, mask, latitude, longitude, coord_x, coord_y, coord_z) # embeddings\n",
    "            embeds.append(emb.detach().cpu().numpy()) # embeddings list\n",
    "\n",
    "    V_embed_bert = cupy.array(np.concatenate(embeds)) # concatenate embeddings --> array\n",
    "    V_embed_bert = V_embed_bert / cupy.linalg.norm(V_embed_bert, ord=2, axis=1, keepdims=True) # l2 normalization\n",
    "    return V_embed_bert # 返回 embeddings\n",
    "\n",
    "def get_embed_model(model_name,fcdim, state_dict,tokenizer):\n",
    "    model = FSMultiModalNet(model_name, fcdim) # 初始化模型\n",
    "    model.to(CFG.device); # 将模型转到GPU\n",
    "    model.load_state_dict(torch.load(state_dict)) # 加载模型参数\n",
    "    embed = get_embed(model,tokenizer) # 获取embedding\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a95125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:13:25.912799Z",
     "iopub.status.busy": "2022-07-05T14:13:25.911934Z",
     "iopub.status.idle": "2022-07-05T14:16:57.321965Z",
     "shell.execute_reply": "2022-07-05T14:16:57.321434Z",
     "shell.execute_reply.started": "2022-07-05T14:03:58.001944Z"
    },
    "papermill": {
     "duration": 211.45033,
     "end_time": "2022-07-05T14:16:57.322102",
     "exception": false,
     "start_time": "2022-07-05T14:13:25.871772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Embedding1\n",
    "embed1 = get_embed_model(CFG_Model1.model_name, 320, CFG_Model1.weight, CFG_Model1.tokenizer)\n",
    "with open('./bert_embed_1/V_embed_bert', 'wb') as f:\n",
    "    pickle.dump(embed1, f)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Embedding2\n",
    "embed2 = get_embed_model(CFG_Model2.model_name, 320, CFG_Model2.weight, CFG_Model2.tokenizer)\n",
    "with open('./bert_embed_2/V_embed_bert', 'wb') as f:\n",
    "    pickle.dump(embed2, f)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Embedding3\n",
    "embed3 = get_embed_model(CFG_Model3.model_name, 320, CFG_Model3.weight, CFG_Model3.tokenizer)\n",
    "with open('./bert_embed_3/V_embed_bert', 'wb') as f:\n",
    "    pickle.dump(embed3, f)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Embedding4\n",
    "embed4 = get_embed_model(CFG_Model4.model_name, 320, CFG_Model4.weight, CFG_Model4.tokenizer)\n",
    "with open('./bert_embed_4/V_embed_bert', 'wb') as f:\n",
    "    pickle.dump(embed4, f)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 363.50342,
   "end_time": "2022-07-05T14:18:23.242645",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-05T14:12:19.739225",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b79a61544c9a744d09395b396d14bdc3ab2980641b64ddb1c7bc6d7b892900a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
